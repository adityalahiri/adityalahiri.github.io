A daily log of little things I learn pertaining to Computer Science and AI/ML.
(Inspired by [Seth Godin](https://seths.blog/))

## 13/10/20

* Need to learn sed, awk and other unix terminal commands to efficiently do analysis over GBs of csv files. Been googling for too long.

## 12/10/20

* Came across [Comp-syn](https://github.com/comp-syn) by a senior of mine. Expresses words as colors! Fascinating.

## 11/10/20

* NA

## 10/10/20

* NA

## 9/10/20

* NA

## 8/10/20

* Learnt the basics of open banking. A big wave is coming!

## 7/10/20

* Why does it always come down to the last day of deadline for paper submissions? The dream is to get it done a few days before and watch.

## 6/10/20

* Used Submodular Pick for SHAP

## 5/10/20

* Came across rephrase.ai that uses GANS for making advertising videos!

## 4/10/20

* NA

## 3/10/20

* Started learning about bitcoin from KhanAcademy!

## 2/10/20

* NA

## 1/10/20

* NA

# 30/9/20

* Came across [this paper](http://proceedings.mlr.press/v97/wei19a/wei19a.pdf) on a new strong interpretable models that uses rules in Generalised Linear Model setting.

## 29/9/20

* Installed a library, got an error, raised [an issue](https://github.com/Trusted-AI/AIX360/issues/104), realized they merged a fix minutes ago, made those changes, and stuff worked. God bless open source!

## 28/9/20

* Disappointing when you see that some academic researchers do not release even a bare-bones working code for their papers. Not even the older papers!

## 27/9/20

* Read [this paper](https://arxiv.org/abs/1807.00595) that combines logic programming with explainability.

## 26/9/20

* Learnt how to automatically update a google sheet when responses in another one come via forms.

## 25/9/20

* NA

## 24/9/20

* NA

## 23/9/20

* Came across [this new library](https://github.com/whylabs/whylogs-python) for doing data profiling. USP->Scalable

## 22/9/20

* Learnt to use the Google Sheets API and used it get data from a google sheet and make a static webpage out of it!

## 21/9/20

* Went across [this wholesome paper](https://www.nist.gov/system/files/documents/2020/08/17/NIST%20Explainable%20AI%20Draft%20NISTIR8312%20%281%29.pdf) by a US Goverment organisation that surveys explainability and ties it up with humans.
* The scary Kwargs is just a dict :)

## 20/9/20

* NA

## 19/9/20

* NA

## 18/9/20

* Had a discussion about how Data Mining and Modelling can be used to distill information from millions of PubMed articles to give a starting point for reusing drugs.

## 17/9/20

* Went over Gradient Boosting and AdaBoost in detail after a long time. Nice refresher!

## 16/9/20

* Difficult to make off the shelf DL based libraries work well for your use case since so many hyperparameters are not available for you to change directly. Have to dive in the source code. Why so many parameters?!

## 15/9/20

* Difficult to decide which ideas one should implement and verify that they work & which one should they discard purely on theoretical grounds. Fine line.

## 14/9/20

* Learnt about a number of new methods to learn rules from data via [this](https://rviews.rstudio.com/2020/05/21/modern-rule-based-models/) article.

## 13/9/20

* NA

## 12/9/20

* NA

## 11/9/20

* Think long and hard about whether the feature you are adding is even needed by people you are building it for, and if it makes logical sense.

## 10/9/20

* Finding relevant metrics to run experiments for is hard!

## 9/9/20

* Came across [this cool webiste](https://aideadlin.es/) for keeping track of conference deadlines.

## 8/9/20

* Read about Online learning of Decision Trees.
* Came across this amazing library for on online learning. [Scikit-multiflow](https://scikit-multiflow.github.io/)

## 7/9/20

* Read [this](https://arxiv.org/pdf/2001.09219.pdf) paper on how explanations can help humans annotate better. Combines Active Learning + Explainability + HCI

## 6/9/20

* NA

## 5/9/20

* NA

## 4/9/20

* Read the paper [Global Explanations of Neural Networks](https://arxiv.org/pdf/1902.02384.pdf)

## 3/9/20

* Tried implementing adversarial training for a linear model in pytorch

## 2/9/20

* Used MLFlow end to end in real life.Super convenient!

## 1/9/20

* Learnt about git reset, stash and resolving BIG merge conflicts in real life setting,again.

## 31/8/20

* NA

## 30/8/20

* NA

## 29/8/20

* NA

## 28/8/20

* Read the paper on [Accurate Intelligible Models with Pairwise Interactions(GAÂ²M )](https://www.cs.cornell.edu/~yinlou/papers/lou-kdd13.pdf)

## 27/8/20

* Read the paper on [Interpret ML](https://arxiv.org/abs/1909.09223)

## 26/8/20

* Attended Hands On Tutorial: Intelligible and Explainable Machine Learning: Best Practices and Practical Challenges at KDD 2020. Learnt about EBMs, an interpretable boosting algorithm and [interpret ml library](http://interpret.ml/)

## 25/8/20

* Attended Research Track Oral Presentations: Interpretable Models at KDD 2020

## 24/8/20

* Attended & Presented at [KDD Workshop on ML In Finance](https://sites.google.com/view/kdd-mlf-2020/home?authuser=0)

## 23/8/20

* Attended [Adversarial Attacks and Defenses: Frontiers, Advances and Practice Tutorial](https://sites.google.com/view/kdd-2020-attack-and-defense) at KDD 20

## 22/8/20

* NA

## 21/8/20

* Looked at [Google's What If tool](https://github.com/PAIR-code/what-if-tool) for visualizing model explanations and fairness.

## 20/8/20

* Read [this very detailed and insightful article](https://www.jeremyjordan.me/testing-ml/) on testing ML frameworks and models

## 19/8/20

* Understood the paper [Robust and Stable Black Box Explanations](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf) better to start writing its summary.

## 18/8/20

* Watched [this overview of Adversarial ML](https://www.youtube.com/watch?v=sucqskXRkss) by Ian Goodfellow at ICLR 19

## 17/8/20

* Started reading a NEURips 2018 tutorial on [adversarial robustness](https://adversarial-ml-tutorial.org/introduction/). It is so good.

## 16/8/20

* NA

## 15/8/20

* NA

## 14/8/20

* Made a first pass through the paper [Robust and Stable Black Box Explanations](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf)

## 13/8/20

* Learnt that [Normalizer in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) works on a sample by sample basis by making the sample have a unit norm. So, the fit() function is basically useless here but the API documentation still does it. Also, this is the reason why it does not have an inverse transform function. 

## 12/8/20

* Attended [Panel Discussion on Model Explainability](https://www.youtube.com/watch?v=B2QBnVnbt7A&utm_source=TWiML+Main&utm_campaign=feae9c95c3-EMAIL_CAMPAIGN_2020_08_11_07_22&utm_medium=email&utm_term=0_68279d0830-feae9c95c3-410869746) hosted by TwimlAI

## 11/8/20

* Found out that there exist Nan and -Nan in C++14. Pretty crazy.

## 10/8/20

* Worked on understanding the paper , Born Again Decision Trees

## 9/8/20

* N/A

## 8/8/20

* N/A

## 7/8/20

* Published a [blog post on LIME](https://arrayslayer.gitbook.io/paw/why-should-i-trust-you-explaining-the-predictions-of-any-classifier-lime) on my paper a week website!

## 6/8/20

* NA

## 5/8/20

* Came across this pre-print book on [Data Feminism](https://data-feminism.mitpress.mit.edu/). Very powerful!
* When stuck with basic ideas in a complex project, it helps to go back and read a seminal book that focuses on basics. Also, it is important to read
with awareness and at the same time not in a way so as to be looking for answers. Reading freely often allows the answers to strike naturally when the moment comes.

## 4/8/20

* Read the section on Logistic Regression from Intro to Statistical Learning to get a detailed refresher!

## 3/8/20

* Read a paper called [Born Again Tree Ensembles](https://arxiv.org/pdf/2003.11132.pdf) from ICML'20. Super neat idea to represent ensembles like Random Forests with one interpretable tree!

## 2/8/20

* Fixed a reproducibility issue in a framework by adding seeds for numpy and torch everywhere. There's got to be a better way to do this?!

## 1/8/20

* N/A

## 31/7/20

* Read [this paper](https://arxiv.org/pdf/2006.12302.pdf) on using GAN to make LIME more robust which is published in KDD 20 Adversarial Learning Workshop.

## 30/7/20

* Started using MLFlow to tract ML experiments for the first time!

## 29/7/20

* The real difficulty when doing incremental changes to an existing ML/DL pipeline is not being sure what else it would break. The need for unit tests
in ML pipelines is one that has to be solved like unit tests do for software.

## 28/7/20

* Spedning some time to decouple your script into functions when you have it fresh and new and understandable is worth it but there is a lot of resistance nonetheless.

## 27/7/20

* UI/UX is a big part of explainability. And its difficult to get right!

## 26/7/20

* N/A

## 25/7/20

* Tried fast-pages by fast-ai.
* Watched [this very morally confusing talk](https://www.youtube.com/watch?v=BaNZ-TMGN3E) on tech companies, capitalism and higher Maslow's needs by Alain de Botton

## 24/7/20

* N/A

## 23/7/20

* Please use arguments in functions to reduce code duplication. For different handling of one line depending on case, do not write a new function!

## 22/7/20

* Generalised DL models that do a lot of stuff vs Deterministic task specific packages? I prefer the latter for now

## 21/7/20

* Recorded my paper's video for presentation at KDD '20. Covid normal!

## 20/7/20

* Tried Plotly with Django for the first time.
* Read [this article from Google Research](https://ai.googleblog.com/2015/08/the-reusable-holdout-preserving.html) to know about a better way of keeping hold out test data.

## 19/7/20

* Used Pytorch's Captum explainability tool's web UI for the first time. Neat!

## 18/7/20

* Created a binary tree using Level Order in Python for the first time!

## 17/7/20

* Attended a talk by Scott Lundberg where he discusses explaininng tree models using SHAP in ICML '220

## 16/7/20

* Came across regex101.com to create programmatic custom regexes in multiple languages easily!

## 15/7/20

* Went through [Robust and Stable Black Box Explanations](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf) paper in ICML'20 wherein they publish a new explainability method which is more robust.

## 14/7/20

* Starting a project on a use case wherein the work is to design a product around the use case! Excited for this product driven kind of work after a dab at research front!

## 13/7/20

* Attended a tutorial on Representation Learning at ICML '20. Model monitoring and Representation Learning are the two areas I want to learn more about this year!

## 12/7/20

* Attended a few expos at ICML '20. Learnt about CLAI, IMBX360, NormLine and other things!

## 11/7/20

* N/A

## 10/7/20

* Read this paper on testing in NLP. [Beyond Accuracy: Behavioral Testing of NLP Models with CheckList](https://www.aclweb.org/anthology/2020.acl-main.442.pdf)

## 9/7/20

* Adding custom edge cases is important but with extensible code!

## 8/7/20

* NA

## 7/7/20

* Started looking at some algorithmic problems!

## 6/7/20

* Planned the next 6 months overview for a project. It is difficult to think and plan and create a realistic and challenging roadmap for projects. Will get better at it with time and experience!

## 5/7/20

* Looked at a few ways/repos to do testing/verification in ML and DL models. Super interesting!

## 4/7/20

* N/A

## 3/7/20

* Learnt about the @classmethod decorator in python. This creates a method that belongs to the class and not to a specific object of the class.

## 2/7/20

* Received my first paper acceptance!!! A new model explainability method. Accepted at KDD workshop on ML In Finance!
* Attended a webinar on Responsible AI by Fiddler.Ai.

## 1/7/20

* Looked at how to write unit tests in python using unittest.mock module

## 30/6/20

* N/A

## 29/6/20

* In bash, don't go for beautiful code styling and put a space on either side of =. It is not assignment anymore!
* In bash, if you want to run a command given in string, put it inside ` and not '.
* Saw [this amazing video](https://www.youtube.com/watch?v=43sjym5ZS68) of the story of Craig Federighi, Senior VP of SWE At Apple.

## 28/6/20

* When starting working with another team, be very iterative. Ask for things that can make the work faster for you shamelessly. And get out some results fast. It is not necessary for those results to be great or perfect. We want both sides to be interested and to help the iterations improve.

## 27/6/20

* Used the DMatrix format directly for the first time to score using a XGBoost model.

## 26/6/20

* Found this new Python feature in latest release that allows merging of dictionaries using the single vertical bar operator. Super cool!

## 25/6/20

* Learnt about the *isinstance* function in Python to check data types

## 24/6/20

* Exploring ties of model explainability with model drift.
* Got the Introduction to Statistical Learning book delivered from Amazon! 

## 23/6/20

* Used the AllenNLP package for the first time for a Symantic Role Labelling task.

## 22/6/20

* Installed PyCharm IDE. Trying out IDEs instead of simple text editors. Let's see how I like it!

## 21/6/20

* Went through the paper [UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION](https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf). Very good and eloquent paper on how we need to re-think how regularisation affects generalisation.
* Listened to a podcast on Rust. Want to explore more on using Rust for ML frameworks.

## 20/6/20

* N/A

## 19/6/20

* Revisited inner join
* Learning the that sometimes sharing your work and convincing people to use it is as difficult as creating the work.

## 18/6/20

* Used iMovie to create a tool demo video! Super cool.

## 17/6/20

* Attended a paper presentation on [Faster Boosting with Smaller Memory](https://papers.nips.cc/paper/9314-faster-boosting-with-smaller-memory.pdf). Faster and accurate boosting algorithm for datasets that do not fit in memory.

## 16/6/20

* Learnt that LD_LIBRARY_PATH environment variable is used to set paths for shared libraries.

## 15/6/20

* Attended a webinar on model drift and model monitoring.

## 14/6/20

* Solved a few algorithmic problems. Minimize max absolute difference in a triplet using 2 pointer was good!

## 13/6/20

* N/A

## 12/6/20

* N/A

## 11/6/20

* Spending time in explaining your work with simple diagrams is necessary if you want people to use it.

## 10/6/20

* Completed initial build of streamlit app to explore explainability methods interactively.

## 9/6/20

* ls -lah to get list of files with size in human readable format.
* Used argparse for the first time

## 8/6/20

* N/A

## 7/6/20

* Used python eval() to just run a command when given a raw string! Deadly!
* Used getattr in python to run a function using its string name

## 6/6/20

* Learnt about ini files and [parsing them in python](https://docs.python.org/3/library/configparser.html).

## 5/6/20

* N/A

## 4/6/20

* N/A

## 3/6/20

* Realised the importance of consistent coding practice like sticking with either camel case or underscores. Mixture of both leads to hell.

## 2/6/20

* Attended [paper presentation](https://openreview.net/pdf?id=r1xMH1BtvB) of [Electra](https://github.com/google-research/electra) NLP Pre-Training by Google Research. One-ups BERT by using Generator + Discriminator in encoder instead of just Generator.

* Started working on [Interactive Interpretability app using Streamlit](https://github.com/arrayslayer/interactive-explainability).

## 1/6/20

* Recalled that in C++, dot works on objects; arrow works on pointers to objects. Use -> when you have a pointer. Use . when you have structure (class).

* Started [this](https://www.coursera.org/learn/data-science-streamlit-python/home/welcome) coursera guided project to learn quick web deployment of interactive data using Streamlit in Python

## 31/5/20

* N/A

## 30/5/20

* N/A

## 29/5/20

* Learnt that "Whenever virtual function is called using base class reference or pointer it cannot be inlined (because call is resolved at runtime), but whenever called using the object (without reference or pointer) of that class, can be inlined because compiler knows the exact class of the object at compile time."

## 28/5/20

* Used df to sql for first time. Intricate

## 27/5/20

* N/A

## 26/5/20

* Learnt the [difference](https://stackoverflow.com/questions/44091886/whats-the-difference-between-virtualenv-and-m-venv-in-creating-virtual-env/44091914) between venv and virtualenv.

## 25/5/20

* Read about [Model Inversion](https://www.cs.toronto.edu/~toni/Courses/Fairness/Lectures/ML-and-DP-v2.pdf).
* Went through [Spacy's Dependency Parser](https://spacy.io/api/dependencyparser).
* Came across a python library for plotting PDP and ICE plots, called [PDPBox](https://github.com/SauceCat/PDPbox)

## 24/5/20

* N/A

## 23/5/20

* Came across [this library](https://github.com/privacytrustlab/ml_privacy_meter) to test how privacy preserving your ML models are.

## 22/5/20

*  Googled for hours figuring out relative imports in python. Crazy! Do not do relative imports please.

## 21/5/20

* N/A

## 20/5/20

* Came across these design ideas from [Polytopal](https://linguafranca.polytopal.ai/) realted to AI to make better AI systems for the end consumer.

## 19/5/20

* Used BibTex for the first time to put in references!

## 18/5/20

*  Realizing that making algorithms parallelized has become a neccessity to run on today's huge scaled data.

## 17/5/20

* Started reading [this article](https://compstat-lmu.github.io/iml_methods_limitations/lime-sample.html) on sampling in LIME.

## 16/5/20

* N/A

## 15/5/20

* N/A

## 14/5/20

* Use %env magic command in jupyter to set environment variables.

## 13/5/20

* Started learning about active learning with [this introductory article at DataCamp.](https://www.datacamp.com/community/tutorials/active-learning)
* Came across this active learning library called [AlpacaTag](https://github.com/INK-USC/AlpacaTag) which allows UI based annotation too

## 12/5/20

* To insert a dict into sql table, best way for now seems to be putting in a string and then use ast literal eval after retreiving it.

## 11/5/20

* Came across text matching using deep learning library called [deepmatcher](https://github.com/anhaidgroup/deepmatcher)
* Found the easiest way in sublime to fix space and tab indentation issues in python.


## 10/5/20

* Went through the [Pytorch 60 minutes blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).

## 9/5/20

* Attented Milind Tambe's (Google Research, AI For Good) webinar to learn about their projects. Super interesting problems!

## 8/5/20

* Submitted my first paper abstract!

## 7/5/20

* Came across this new time zone called Anywhere On Earth, which is the most lagging time zone, ie, everyhwere else the day is completed before this time zone completes their day!

## 6/5/20

* Learnt about [literal_eval](https://kite.com/python/docs/ast.literal_eval) in python for interpreting and parsing strings as python commands!
* Used [fuzzyset](https://pypi.org/project/fuzzyset/) for the first time.

## 5/5/20

* N/A

## 4/5/20

* Listened to [this Self Explaining AI discussion](https://podcasts.google.com/?feed=aHR0cHM6Ly9kYXRhc2tlcHRpYy5saWJzeW4uY29tL3Jzcw&ep=14&episode=OWI2NDY2MjgtNTllZC00YjU1LTg4MTUtZjVhMWNiZGJjNzdm). Very interesting idea.


## 3/5/20

* [Passing variable into bash(!)](https://stackoverflow.com/questions/35497069/passing-ipython-variables-as-arguments-to-bash-commands) command in Jupyter.

## 2/5/20

* N/A

## 1/5/20

* N/A

## 30/4/20

* [Easy progress bar for any pandas apply operation](https://stackoverflow.com/questions/18603270/progress-indicator-during-pandas-operations). Anxiety Saver!


## 29/4/20

* Finally used ravel() in real life.
* Get only idf from tfidf vectorizer in sklearn using _idf attribute

## 28/4/20

* Send one hot labels in OneVsRest to make it multi label.

## 27/4/20

* Famous papers have shady experiments and even shadier implementations.
* Simply used nlp("Sentence...").vector in SpaCy to get consistent dimensions embeddings for any sentence!
* Learnt that [sklearn does a linear normalization](https://stats.stackexchange.com/questions/374913/summing-predicted-probabilities-from-logistic-regression-using-one-vs-rest) (not softmax!) of all output probabilites

## 26/4/20

* [Chapter 2](https://course.spacy.io/en/chapter2) of the Advanced NLP with SpaCy course.
* The importance of constraints while working on a problem. Read [How can Data Scientists survive layoffs?](https://peadarcoyle.com/2020/04/26/how-can-data-scientists-survive-layoffs/)

## 25/4/20

* N/A

## 24/4/20

* Used [Count Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for the first time. And understood it.(Two very different things!)
* Started with [this Adv NLP with SpaCy](https://course.spacy.io/) interactive course!

## 23/4/20

* Used "Convert to Smart Art" in powerpoint for first time. Handy life hack!
* Reminder that PCA is deterministic as no parameters.

## 22/4/20

* Used Solr for the first time.
* Made changes inside a library's code which makes me wonder how 99% of work is understanding the code and 1% is adding your stuff in it.


## 21/4/20

* [Setup remote local sftp on Sublime](https://medium.com/@daniwhkim/remote-ftp-sftp-with-sublime-de7d71a2b400). Life gets simpler!
* Wrote the first functional test of my life. Hard work!


## 20/4/20

* Symlinks! Used Symlink in [Jupyter](https://cyberhelp.sesync.org/faq/how-to-create-a-symlink-to-research-directory-in-Jupyter-lab.html) to get another folder in sidebar to access files on server. So, neat!
* Learnt why people simply do not use one hot econding instead of embeddings in text models -> High dimensionality!

## 19/4/20

* Discovered [LALE](https://github.com/IBM/lale) library by IBM for semi automated Data Science workflow.
* Read Chapter 1 of the [Causal Reasoning Book](https://causalinference.gitlab.io/causal-reasoning-book-chapter1/). Coming to this after reading The Book Of Why and wanting a more machine learning oriented resource. Aim to use Causal Reasoning as aid to Machine Learning Interpretability.

## 18/4/20

* N/A

## 17/4/20

* Used Multioutput classification for the first time

## 16/4/20

* Used tf-idf irl for first time.
* Read about [dataset shift](https://www.analyticsvidhya.com/blog/2017/07/covariate-shift-the-hidden-problem-of-real-world-data-science/)

## 15/4/20

N/A

## 14/4/20

* Realized that I should brush up on SQL and not resort to doing everything via pandas.
* Found this new pandas function to stack columns down. [pd.stack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html)

## 13/4/20

* Ctrl+Shift+P and then clear cell output to clear the output of a current Jupyter cell
* Found this [spelling correction library](https://github.com/wolfgarbe/SymSpell)

## 12/4/20

* Read this [new paper](https://arxiv.org/abs/2002.11097) that highlights the problems in using Shapely values for feature attribution.
* Got mind blown by Microsoft's Power Point's [enhanced design recommendations](https://www.microsoft.com/en-us/microsoft-365/blog/2019/06/18/powerpoint-ai-upgrade-designer-major-milestone-1-billion-slides/)!

## 11/4/20

* Went through [Stanford's Karel Bot](https://compedu.stanford.edu/karel-reader/docs/python/en/chapter1.html)which used to teach Intro to programming at Stanford. So neat!

## 10/4/20

* If stuck between too many little fixes, just start all over again! Far more efficient.
* Discovered Google's [diff_match_patch](https://github.com/google/diff-match-patch) to find diff, match and patch (:P) text.
* Appreciating the need to write quality generalised tests for modules! Avoid hard coding as much as you 
